{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this notebook to be run in the fashion_MNIST environment\n",
    "### requires tensorflow, keras, opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17383712889744092692\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6692228956\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5728126988690324429\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras import regularizers, optimizers, Model\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 256\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape: (19800, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load and transform data\n",
    "mnist_data = fashion_mnist.load_data()\n",
    "x = mnist_data[0][0]\n",
    "y = mnist_data[0][1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .33, random_state = 41)\n",
    "\n",
    "# reshape for NN tensors\\\n",
    "if K.image_data_format() == \"channels first\":\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# cast to a 32 bit float and then scale so the value is a float between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 225\n",
    "x_test = x_test.astype(\"float32\") / 225\n",
    "\n",
    "# convert class vector to binary class matrices (one hot encode)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_test shape: {}'.format(str(y_test.shape)))\n",
    "\n",
    "# function to devoce one-hot-encoding later on when we want to evaluate performance\n",
    "def decode_one_hot(y):\n",
    "    y_classes = [np.argmax(yi, axis = None, out = None) for yi in y]\n",
    "    return y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data exploration\n",
    "n = random.randint(0, x_train.shape[0] - 1)\n",
    "\n",
    "def random_block(input_matrix):\n",
    "    '''\n",
    "    input matrix is expected to be (28, 28, 1)\n",
    "    '''\n",
    "    size = input_matrix.shape\n",
    "    w = size[0] // 4\n",
    "    h = size[1] // 4\n",
    "    c = 0\n",
    "    loc = (random.randint(0 + w // 2, size[0] - w - w // 2),\n",
    "           random.randint(0 + h // 2, size[1] - h - h // 2))\n",
    "    \n",
    "    input_matrix_copy = input_matrix.copy()\n",
    "    \n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            input_matrix_copy[loc[0] + i, loc[1] + j, 0] = c\n",
    "\n",
    "            j+=1\n",
    "        i+=1\n",
    "\n",
    "    return input_matrix_copy\n",
    "\n",
    "plt.figure()\n",
    "#plt.imshow(x_train[n][:,:].reshape(28,28)) # reshape just gets rid of the extra dim (28,28,1)\n",
    "plt.imshow(random_block(x_train[n][:,:]).reshape(28,28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up image data generator\n",
    "datagen = ImageDataGenerator(rotation_range = 0,\n",
    "                            horizontal_flip = False,\n",
    "                            fill_mode = 'constant',\n",
    "                            cval = 0,\n",
    "                            width_shift_range = 2,\n",
    "                            height_shift_range = 2,\n",
    "                            zoom_range = 2,\n",
    "                            preprocessing_function = random_block)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training function\n",
    "def train(augmentation, epochs):\n",
    "    '''\n",
    "    This function is used to train the model and print out stats.\n",
    "    Model must be compiled first.\n",
    "    my_callbacks must be defined first.\n",
    "    '''\n",
    "    if not augmentation:\n",
    "        print('NOT using image augmentation')\n",
    "        hist = model.fit(x_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        verbose = 1,\n",
    "                        validation_data = (x_test, y_test),\n",
    "                        callbacks=my_callbacks)\n",
    "        \n",
    "    else:\n",
    "        print('using image augmentation')\n",
    "        hist = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                                batch_size = batch_size),\n",
    "                                   steps_per_epoch = len(x_train)/batch_size,\n",
    "                                   validation_data = (x_test, y_test),\n",
    "                                   epochs = epochs,\n",
    "                                   verbose = 1,\n",
    "                                   callbacks = my_callbacks,\n",
    "                                   workers = 2)\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    yhat = model.predict_classes(x_test).astype(int)\n",
    "    y_dec = decode_one_hot(y_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_dec, yhat))\n",
    "    print('Testing Loss: {}'.format(score[0]))\n",
    "    print('Testing Accuracy: {}'.format(score[1]))\n",
    "    print(model.summary())\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(hist):\n",
    "    epoch_list = list(range(1, len(hist.history['acc']) + 1))\n",
    "    plt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\n",
    "    plt.legend((\"Training Accuracy\", \"Validation Accuracy\"))\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epoch_list, hist.history['loss'], epoch_list, hist.history['val_loss'])\n",
    "    plt.legend((\"Training Loss\", \"Validation Loss\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3)))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100)) # Try removing or adding this layer to improve performance\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# Having trouble getting tensorboard callback to work well with EarlyStopping callback...\n",
    "\n",
    "my_callbacks = [ModelCheckpoint('baseline.hdf5', monitor='acc', save_best_only=True, save_freq=1)]\n",
    "\n",
    "model.compile(optimizer,\n",
    "              loss = tf.keras.losses.categorical_crossentropy,\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using image augmentation\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-53840de9ecfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit and evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-64be51fc8d9b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(augmentation, epochs)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                    \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                                    workers = 2)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m   1132\u001b[0m           call_from_convolution=False)\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# copybara:strip_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[1;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m   1032\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[0;32m   1128\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0;32m   1129\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1130\u001b[1;33m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[0;32m   1131\u001b[0m   _execute.record_gradient(\n\u001b[0;32m   1132\u001b[0m       \"Conv2D\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\.conda\\envs\\fashion_MNIST\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate model\n",
    "hist = train(True, 50)\n",
    "plot_results(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion_MNIST",
   "language": "python",
   "name": "fashion_mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
